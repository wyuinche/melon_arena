{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "token_tag.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyN1cwo4f4/I2/WUqpkfXekO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wyuinche/melon_arena/blob/master/token_tag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVrb3puU89Js",
        "colab_type": "text"
      },
      "source": [
        "##**아래건 카이 때문입니다 안해도 될거 같아유**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4NLX8GB95wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/kakao/khaiii.git\n",
        "!pip install cmake\n",
        "!mkdir build\n",
        "!cd build && cmake /content/khaiii\n",
        "!cd /content/build/ && make all\n",
        "!cd /content/build/ && make resource\n",
        "!cd /content/build && make install\n",
        "!cd /content/build && make package_python\n",
        "!pip install /content/build/package_python\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ85Ss7-DckU",
        "colab_type": "text"
      },
      "source": [
        "우리의 필요한 라이브러리들 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZsrVwyVJ36y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from collections import Counter\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import re\n",
        "from typing import *\n",
        "#from khaiii import KhaiiiApi  ##요건 khaiii쓰면 해주세요\n",
        "from tqdm import tqdm\n",
        "from time import sleep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGhMZlhUVQic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#구글 드라이브 아니면 지워주세요 :)\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzf-jq1ZVSaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_path = your_path :)\n",
        "token = pd.read_json('/gdrive/My Drive/Colab Notebooks/token_final.json', orient = 'table')\n",
        "test = pd.read_json('/gdrive/My Drive/Colab Notebooks/test_token.json', orient='table' ) #얘는 그 제가 kahiii썼다는 가정하에 token만들어서 test에 붙여놓은거에요\n",
        "val = pd.read_json('/gdrive/My Drive/Colab Notebooks/val_token.json', orient='table')\n",
        "#test = pd.read_json('/gdrive/My Drive/Colab Notebooks/test.json', typ='frame', encoding='utf-8')\n",
        "#val = pd.read_json('/gdrive/My Drive/Colab Notebooks/val.json', typ='frame', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgHmpHDcWa99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#이건 빈 게 뭔지 알라구 하는 거:)\n",
        "#if len(test['plylst_title'][0])==0:\n",
        "  #print('yes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCYRIdrCfMhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#이것두 그냥 하고 싶어서임 ㅇㅇ\n",
        "#if len(test['plylst_title'][5]) != 0:\n",
        "#  print('yes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug1Sds0U833k",
        "colab_type": "text"
      },
      "source": [
        "#이건 토큰화 하는 함수입니다. 토큰화 되면 안해도 되요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWFqK-2MHZRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = KhaiiiApi()\n",
        "#플레이리스트에서 공백은 일단 채워둘게요\n",
        "def re_sub(series: pd.Series) -> pd.Series:\n",
        "    series = series.str.replace(pat=r'[ㄱ-ㅎ]', repl=r'', regex=True)  # ㅋ 제거용\n",
        "    series = series.str.replace(pat=r'[^\\w\\s]', repl=r'', regex=True)  # 특수문자 제거\n",
        "    series = series.str.replace(pat=r'[\\u3000]+', repl=r'', regex=True)  # u3000 제거\n",
        "    return series\n",
        "\n",
        "#토큰 가져오기\n",
        "def get_token(title: str, tokenizer)-> List[List]:\n",
        "    \n",
        "    if len(title)== 0 or title== ' ':  # 제목이 공백인 경우 tokenizer에러 발생\n",
        "        return []\n",
        "    \n",
        "    result = tokenizer.analyze(title)\n",
        "    result = [[morph.lex, morph.tag] for split in result for morph in split.morphs]  # (형태소, 품사) 리스트의 리스트\n",
        "    return result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtfQRy679lzQ",
        "colab_type": "text"
      },
      "source": [
        "이건 토큰화 되었을 때, 토큰-tag 맵핑 json을 이용해서 플레이리스트에서 태그 10개 추출하는 것입니다. 여기 문제는 일단 무조건 10개 뽑는겁니다. 중복이 안되면 소용이 없다는게 제일 큰 문제네요ㅠㅠ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX5X-D1O81Ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sort_tag(i, j, k):\n",
        "  icm.extend(token['tags'][k]) #태그를 test에 추가해준다\n",
        "  vocab = Counter(icm)  # tag중에 중복이 많은거 위주로 카운트한다\n",
        "  vocab_size = 10 # 중복 많은거 중 10개까지, 근데 문제는 10개가 안되도 10개가 뽑힌다\n",
        "  vocab = vocab.most_common(vocab_size) #중복 없이 추출된건 가장 왼쪽에 있는 거라서 기준이 없다\n",
        "  for x in range(len(vocab)): #vocab 길이만큼 추가~\n",
        "    test['tags'][i].append(vocab[x][0]) # 태그에 추가한다 extend로 하니까 음절단위로 끊겨서 append로 해야 하네요\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpumZu7VIwN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "using_pos = ['NNG','SL','NNP', 'XR', 'VA'] #일반명사, 외국어, 고유명사, 어근, 형용사 만 사용할거입니다\n",
        "rid=['노래','때', '좋', '모음', '곡',  '날', '야', '동', '같', '지',  '추천', '트', '요즘', '이', '없', '속', '스', '전', '을', '를', '로', '디', '래', '후', '라']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M94GJk7d918h",
        "colab_type": "text"
      },
      "source": [
        "이건 각각의 플레이리스트 타이틀에서 토큰을 뽑는 방법입니다. usingpos로 품사를 정하고, rid로 stopword 불용어를 제거해서 나타낸 방법입니다. 만약 test_token, val_token쓰시면 이 부분은 안해도 됩니다만 원래는 해야겠죠"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYC-TnJKJSWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['plylst_title'] = re_sub(test['plylst_title'])\n",
        "test.loc[:,'1'] = test['plylst_title'].map(lambda x: get_token(x, tokenizer))\n",
        "test['2'] = test['1'].map(lambda x: list(filter(lambda x: x[1] in using_pos, x)))\n",
        "test['3'] = test['2'].map(lambda x: list(filter(lambda x: not x[0] in rid, x)))\n",
        "test['plylst_token'] = test['3'].map(lambda x: [tag[0] for tag in x])\n",
        "test = test.drop(['1'], axis =1)\n",
        "test = test.drop(['2'], axis =1)\n",
        "test = test.drop(['3'], axis =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSgj4-jZZxtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val['plylst_title'] = re_sub(val['plylst_title'])\n",
        "val.loc[:,'1'] = val['plylst_title'].map(lambda x: get_token(x, tokenizer))\n",
        "val['2'] = val['1'].map(lambda x: list(filter(lambda x: x[1] in using_pos, x)))\n",
        "val['3'] = val['2'].map(lambda x: list(filter(lambda x: not x[0] in rid, x)))\n",
        "val['plylst_token'] = val['3'].map(lambda x: [tag[0] for tag in x])\n",
        "val = val.drop(['1'], axis =1)\n",
        "val = val.drop(['2'], axis =1)\n",
        "val = val.drop(['3'], axis =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmv6IvI6bA12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val = val.drop(['1'], axis =1)\n",
        "val = val.drop(['2'], axis =1)\n",
        "val = val.drop(['3'], axis =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp_RO9skA_Lp",
        "colab_type": "text"
      },
      "source": [
        "tqdm은 진행현황알려구"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCeoAbnIfZJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in tqdm(range (10739)): #전체 테스트 개수에 대해서 // 나중에 분담해도 될듯?\n",
        "  if len(test['plylst_token'][i]) !=0: #토큰이 1개라도 뽑히면\n",
        "    icm = []\n",
        "    for j in range(len(test['plylst_token'][i])): #토큰의 개수에 따라 \n",
        "      for k in range(len(token)): #토큰_태그 개수만큼 34901\n",
        "        if test['plylst_token'][i][j] == token[\"token\"][k]: #이 토큰을 토큰_태그에서 찾아서 \n",
        "          sort_tag(i, j, k)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}